# -*- coding: utf-8 -*-
"""the iris database but now with a real time prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbFoeTL_QouuM0QyVdCCGMMEbTzpPawm

classification is diff b/w data points and separating them into classes.
"""

!pip install -q sklearn

"""iris data set"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
from __future__ import absolute_import, division,print_function,unicode_literals
import tensorflow as tf
import pandas as pd

import tensorflow.compat.v2.feature_column as fc

CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth','PetalLength','PetalWidth','Species']
SPECIES = ['Setosa','Versicolor','Virginica']

train_set = tf.keras.utils.get_file(
    "iris_training.csv","https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
test_set = tf.keras.utils.get_file(
    "iris_test.csv","https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

train=pd.read_csv(train_set,names=CSV_COLUMN_NAMES,header=0)
test=pd.read_csv(test_set,names=CSV_COLUMN_NAMES,header=0)
"""we are using keras(submodule of tensorflow) to grab the dataset and read it into pandas dataframe"""
test.head()

y_train=train.pop("Species")
y_test=test.pop('Species')
train.shape

y_train.head()

#input function for the data batch
def input_fn(features,labels,training=True,batch_size=256):
  #convert the inputs to dataset
  dataset=tf.data.Dataset.from_tensor_slices((dict(features),labels))
  #shuffle the dataset for randomized inputs 
  if training:
    dataset=dataset.shuffle(1000).repeat()
  return dataset.batch(batch_size)

"""feature column for the input function"""

#feature columns for the input function
featured_columns=[]
for key in train.keys():#gives us all the columns
  featured_columns.append(tf.feature_column.numeric_column(key=key))
print(featured_columns)

# we build a DNN for the model 
classifier = tf.estimator.DNNClassifier(
    feature_columns=featured_columns,
    #the hidden layers (2 hidden layers nodes 30 and 10 )
    hidden_units=[30, 10],
    #the model then chooses between the 3 classes
    n_classes=3)

# now we train the model not to fight o lol, to classify
classifier.train(
    input_fn=lambda: input_fn(train,y_train,training=True), # to reduce function conflicts we used lamba, not otunba lamba, i'm too funny abeg
    steps=5000)

#evaluate the model
eval_result=classifier.evaluate(input_fn=lambda: input_fn(test,y_test, training=False))
print('\n Test set accuracy: {accuracy:0.3f}\n'.format(**eval_result))

#prediction no label because we want the model to do so
def input_fn(features,batch_size=256):
  #change inputs to dataset
  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)
features=['SepalLength','SepalWidth','PetalLength','PetalWidth']
predict={}
print("type the values")
for feature in features:
  valid=True
  while valid:
    value=input(feature + ":")
    if not value.isdigit(): valid=False
  predict[feature] = [float(value)]
predictions = classifier.predict(input_fn=lambda: input_fn(predict))
for predikts in predictions:
  class_id=predikts['class_ids'][0]
  probability=predikts['probabilities'][class_id]

  print('prediction is "{}" ({:.1f}%)'. format(
      SPECIES[class_id],100*probability))